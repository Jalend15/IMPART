https://arxiv.org/pdf/1903.01489v1
https://sites.google.com/site/describingmovies/ 
https://www.cs.utexas.edu/users/ml/clamp/videoDescription/#description 

Microsoft Research Video Description Corpus (MSVD): Also known as "YouTubeClips", this dataset contains about 2,000 video clips sourced from YouTube. Each clip is annotated with multiple descriptions which are useful for training models on video captioning.

Movie Description Corpus (M-VAD): This dataset is specifically aimed at providing audio descriptions for movies. It contains descriptions for thousands of movie clips, which are derived from DVDs that included descriptive video service (DVS) tracks.

Large Scale Movie Description Challenge (LSMDC): This dataset combines the M-VAD dataset and the MPII-MD dataset, featuring a large collection of movie clips with corresponding descriptive text. It's particularly used in annual challenges that focus on automatic video description.

MPII Movie Description Dataset (MPII-MD): Focused on automatic movie description, this dataset offers approximately 68,000 sentences and 94 hours of video across 42 movies. The sentences are aligned to the video clips, making it suitable for training and evaluating video description models.